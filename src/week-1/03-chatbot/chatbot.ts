import dotenv from "dotenv";
import OpenAI from "openai";
import readline from "node:readline";

dotenv.config();
const client = new OpenAI();

const consoleReader = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

const ask = (question: string) =>
  new Promise<string>((resolve) => consoleReader.question(question, resolve));

async function chatbot() {
  console.log(
    `
      ðŸš€ Rozpocznij rozmowÄ™ zadajÄ…c pytania
      ðŸ’¡ Czatbot pamiÄ™ta caÅ‚Ä… historiÄ™ rozmowy, aÅ¼ jej nie zakoÅ„czysz
      âŒ Aby zakoÅ„czyÄ‡ rozmowÄ™, napisz "koniec"
    `,
  );

  let previousResponseId: string | undefined = undefined;

  while (true) {
    const userInput = (await ask("Ty: ")).trim();

    if (userInput.toLowerCase() === "koniec") {
      console.log("Do zobaczenia!");
      break;
    }

    const response: OpenAI.Responses.Response = await client.responses.create({
      model: "gpt-5-nano",
      input: userInput,
      // NOTE: previous_response_id Å‚Ä…czy odpowiedzi w jednÄ… historiÄ™ rozmowy
      previous_response_id: previousResponseId,
    });

    console.log(`AI: ${response.output_text}`);

    // NOTE: zapamiÄ™tuje identyfikator bieÅ¼Ä…cej odpowiedzi, Å¼eby w nastÄ™pnej iteracji
    // przekazaÄ‡ go jako previous_response_id i zachowaÄ‡ historiÄ™ rozmowy
    previousResponseId = response.id;
  }

  consoleReader.close();
}

chatbot().catch((error) => {
  console.error("BÅ‚Ä…d:", error);
  consoleReader.close();
});
